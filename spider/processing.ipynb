{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping metadata\n",
    "\n",
    "First, we need to scrape the metadata of the images. In the API provided by [Civitai](https://civitai.com/), the metadata is stored in paginated form, which we can access through the [models](https://github.com/civitai/civitai/wiki/REST-API-Reference#models) API. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python SUR_meta_spider.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data\n",
    "\n",
    "Since the scraped metadata is stored in JSON files, we then need to clean and merge the data. We store the processed data in `data.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "file_list = glob.glob(\"data/meta-*.json\")\n",
    "data = {\"metadata\": {\"totalItems\": 0, \"totalPages\": 0}, \"items\": []}\n",
    "\n",
    "for i in file_list:\n",
    "    with open(i, \"r\") as f:\n",
    "        data[\"items\"].extend(json.load(f)[\"items\"])\n",
    "        \n",
    "data[\"metadata\"][\"totalPages\"] = len(file_list)\n",
    "data[\"metadata\"][\"totalItems\"] = len(data[\"items\"])\n",
    "\n",
    "print('totalPages', data[\"metadata\"][\"totalPages\"])  \n",
    "print('totalItems', data[\"metadata\"][\"totalItems\"])  \n",
    "\n",
    "\n",
    "image_data = {\"metadata\": {\"totalItems\": 0, \"imageItems\": 0, \"repetitionItems\": 0, \"ReDupItems\": 0}, \"items\": []}\n",
    "count = 0\n",
    "for i in data[\"items\"]:\n",
    "    image_lists = i[\"modelVersions\"]\n",
    "    for image_list in image_lists:\n",
    "        for k in image_list[\"images\"]:\n",
    "            count += 1\n",
    "            try:\n",
    "                new_k = {}\n",
    "                new_k[\"url\"] = k[\"url\"]\n",
    "                new_k[\"prompt\"] = k[\"meta\"][\"prompt\"]\n",
    "                try:\n",
    "                    new_k[\"negativePrompt\"] = k[\"meta\"][\"negativePrompt\"]\n",
    "                except:\n",
    "                    new_k[\"negativePrompt\"] = \"\"\n",
    "                    \n",
    "                image_data[\"items\"].append(new_k)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "image_data[\"metadata\"][\"totalItems\"] = count\n",
    "image_data[\"metadata\"][\"imageItems\"] = len(image_data[\"items\"])\n",
    "print('totalImages', image_data[\"metadata\"][\"totalItems\"])  \n",
    "print('totalImages with prompt', image_data[\"metadata\"][\"imageItems\"])  \n",
    "\n",
    "\n",
    "url_dict = {}\n",
    "url_total = {}\n",
    "origin_image_item = image_data[\"items\"]\n",
    "image_data[\"items\"] = []\n",
    "\n",
    "for i in origin_image_item:\n",
    "    url_list = i[\"url\"].split(\"/\")\n",
    "    image_name = url_list[-3]\n",
    "    if url_dict.get(image_name, -1) == -1:\n",
    "        i[\"image_name\"] = image_name\n",
    "        image_data[\"items\"].append(i)\n",
    "        url_dict[image_name] = 1\n",
    "        url_total[image_name] = [i]\n",
    "    else:\n",
    "        url_total[image_name].append(i)\n",
    "        \n",
    "count = 0 \n",
    "for k, v in url_total.items():\n",
    "    if len(v) != 1:\n",
    "        count += 1\n",
    "\n",
    "image_data[\"metadata\"][\"repetitionItems\"] = count\n",
    "image_data[\"metadata\"][\"ReDupItems\"] = len(image_data[\"items\"])\n",
    "print(\"repetition count\", count) \n",
    "print(\"totalImages after deduplication\", image_data[\"metadata\"][\"ReDupItems\"])\n",
    "\n",
    "with open(\"data/data.json\", \"w\") as f:\n",
    "    json.dump(image_data, f)\n",
    "    \n",
    "image_data[\"items\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping images\n",
    "\n",
    "Due to the very large total number of images, we highly recommend that if users intend to scrape all the images, they should consider modifying the code to implement multiprocessing for the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python SUR_image_spider.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating captions for images\n",
    "\n",
    "If users are generating captions for a large number of images, we highly recommend that they modify the code to support batch processing and multi-GPU parallel mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lavis.models import load_model_and_preprocess\n",
    "from PIL import Image\n",
    "import torch\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cuda = 0\n",
    "device = torch.device(f\"cuda:{cuda}\" if torch.cuda.is_available() else \"cpu\")\n",
    "blip_model, vis_processors, _ = load_model_and_preprocess(name=\"blip_caption\", model_type=\"base_coco\", is_eval=True, device=device)\n",
    "\n",
    "\n",
    "with open(\"data/data.json\", \"r\") as f:\n",
    "    data = json.load(f)[\"items\"]\n",
    "print(len(data))\n",
    "\n",
    "with open(f\"data/metadata.jsonl\", \"w\") as f: \n",
    "    for i in range(len(data)):\n",
    "        raw_image = Image.open(f\"image/{data[i]['image_name']}.png\").convert(\"RGB\")\n",
    "        image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "        caption = blip_model.generate({\"image\": image})[0]\n",
    "        json.dump({\"file_name\": data[i]['image_name'], \"text\": caption, \"prompt\": data[i]['prompt']}, f)\n",
    "        f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the vector of `text`\n",
    "\n",
    "The final step of data processing involves extracting the vector for the `text` (image caption) from [llama](https://github.com/facebookresearch/llama). For the processing workflow, please refer to the [Prompt2vec](https://github.com/Qrange-group/SUR-adapter#-prompt2vec)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
